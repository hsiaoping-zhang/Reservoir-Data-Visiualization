{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 水庫資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0                    1      2      3       4       5        6        7   \\\n",
      "9  鯉魚潭水庫  2019-04-20 23:00:00  18.09  50.93  287.17  300.00  6655.71  58.14 %   \n",
      "\n",
      "     8   9   10  11    12    13  14  15  16  \n",
      "9  7.28  --  --  --  0.00  0.30  --  --  --  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['石門水庫',\n",
       " '翡翠水庫',\n",
       " '寶山第二水庫',\n",
       " '永和山水庫',\n",
       " '明德水庫',\n",
       " '鯉魚潭水庫',\n",
       " '德基水庫',\n",
       " '石岡壩',\n",
       " '霧社水庫',\n",
       " '日月潭水庫',\n",
       " '湖山水庫',\n",
       " '仁義潭水庫',\n",
       " '白河水庫',\n",
       " '烏山頭水庫',\n",
       " '曾文水庫',\n",
       " '南化水庫',\n",
       " '阿公店水庫',\n",
       " '牡丹水庫']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get reservoir list from \"Statistics\" website ###\n",
    "url = \"http://fhy.wra.gov.tw/ReservoirPage_2011/Statistics.aspx\"  # \n",
    "table = pd.read_html(url)\n",
    "\n",
    "total_reservoir = list(table[0][0][4:-1])\n",
    "total_reservoir.remove(\"集集攔河堰\")  # can not grab from the website\n",
    "total_reservoir.remove('高屏溪攔河堰')  # can not grab from the website\n",
    "\n",
    "table = table[0]\n",
    "print(table[table[0] == '鯉魚潭水庫'])\n",
    "\n",
    "table.index = table[0]\n",
    "total_reservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 測試一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"http://fhy.wra.gov.tw/ReservoirPage_2011/StorageCapacity.aspx\"  # website url\n",
    "table = pd.read_html(url)  # use pandas to read html form\n",
    "print(\"type: \", type(table))  # list type\n",
    "table[0].head()  # table[0] is DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "欄位內容 :\n",
    "#### 0: 水庫名稱\n",
    "#### 1: sum capacity 有效容量(萬立方公尺)\n",
    "#### 2: time period 起迄時間\n",
    "#### 3: rain 降雨量(毫米)\n",
    "#### 4: in water 進水量(萬立方公尺)\n",
    "#### 5: out water 出水量(萬立方公尺)\n",
    "#### 6: water level difference 水位差(公尺)\n",
    "#### 7: time 水情時間\n",
    "#### 8: current water level 水位(公尺)\n",
    "#### 9: current water capacity 有效蓄水量(萬立方公尺)\n",
    "#### 10: water capacity percentage 蓄水百分比(百分比)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawler 網路爬蟲 - 以水庫資料為例\n",
    "<br>\n",
    "##### http://fhy.wra.gov.tw/ReservoirPage_2011/StorageCapacity.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "這個函式會找特定的 value ，如「__VIEWSTATE」等\n",
    "'''\n",
    "def find_value(name, web):\n",
    "    reg = 'name=\"' + name + '\".+value=\"(.*)\" />'\n",
    "    pattern = re.compile(reg)\n",
    "    result  = pattern.findall(web.text)\n",
    "    try:\n",
    "        return result[0]\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "處理DataFrame type的資料，並從index list當中獲得要存取的欄位，\n",
    "加到reservoir_dict_list當中(由不同欄位資料的dictionary組成的list type)，並回傳\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_data_management(table, reservoir_dict_list, total_reservoir, index):\n",
    "    table.index = table[0]  # set column 1 values to be index\n",
    "    \n",
    "    for num in range(len(index)):  # scan for each value we want to get(capacity, percentage...)\n",
    "        for item in total_reservoir:\n",
    "            value = table.at[item, index[num]]  # access value by reservoir name and column number\n",
    "            \n",
    "            try:\n",
    "                value = float(value)  # try to convert value from string type to float\n",
    "            except BaseException:  # exception: \"--\" or \"XX.xx%\"\n",
    "                if(\"%\" in value):  # percentage case\n",
    "                    value = float(value.replace(\"%\", \"\"))  # remove char %\n",
    "                else:\n",
    "                    value = \"NULL\"  # nan case\n",
    "                    \n",
    "            if(item in list(reservoir_dict_list[num].keys())):  # dict[item] has been created\n",
    "                reservoir_dict_list[num][item].append(value)\n",
    "            else:  # dict[item] has not been created\n",
    "                reservoir_dict_list[num][item] = [] # creat a list container\n",
    "                reservoir_dict_list[num][item].append(value)\n",
    "                \n",
    "    return reservoir_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "因為這個網頁進行爬蟲時，需要 __EVENTTARGET 和 __VIEWSTATE 兩個參數才能順利獲得查詢資料，\n",
    "而兩個參數會隨每天而有所不同，因此必須先用 GET 的方式存取到兩個參數的值，\n",
    "接著建立參數們，放入剛剛抓取到的驗證碼及查詢時間格式，\n",
    "用 POST 方式向網頁抓取資料，最後藉著得到的網頁資訊進行資料的提取。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reservoir_data_search(date, reservoir_dict_list, total_reservoir, index):\n",
    "    # open browser\n",
    "    ses = requests.Session()\n",
    "\n",
    "    # enter the website\n",
    "    d = ses.get('http://fhy.wra.gov.tw/ReservoirPage_2011/StorageCapacity.aspx')\n",
    "    \n",
    "    # parameter list\n",
    "    load_list = [find_value(\"__EVENTTARGET\", d), find_value(\"__VIEWSTATE\", d)]\n",
    "    if(date[2] == \"1\"):  # just take a look at schedule\n",
    "        print(\"yy/mm/dd:\", date)\n",
    "    \n",
    "    # website request needs POST parameter\n",
    "    payload = {\n",
    "        \"__EVENTTARGET\": load_list[0],\n",
    "        \"__VIEWSTATE\": load_list[1],\n",
    "        'ctl00$cphMain$cboSearch': \"所有水庫\",\n",
    "        'ctl00$cphMain$ucDate$cboYear': date[0],\n",
    "        'ctl00$cphMain$ucDate$cboMonth': date[1],\n",
    "        'ctl00$cphMain$ucDate$cboDay': date[2],\n",
    "\n",
    "    }\n",
    "    # request to website using POST\n",
    "    res = requests.post(\"http://fhy.wra.gov.tw/ReservoirPage_2011/StorageCapacity.aspx\", data = payload)\n",
    "    # manage table data\n",
    "    reservoir_dict_list = table_data_management(pd.read_html(res.text)[0], reservoir_dict_list, total_reservoir, index)\n",
    "    \n",
    "    '''\n",
    "    如果要用解析html的方法進行資料提取，程式碼為：\n",
    "    soup = BeautifulSoup(res.text, \"lxml\").find_all(\"tr\")[2:]  # 從<tr>下手\n",
    "    reservoir_dict_list = reservoir_data_management(soup, reservoir_dict)\n",
    "    \n",
    "    ** 最下面的函式 reservoir_data_management() 是以只存取 percentage 為例 **\n",
    "    '''\n",
    "    \n",
    "    return reservoir_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "從 dict_list 當中一個個提取欄位的 dictionary，並寫成 csv 檔\n",
    "\n",
    "parameter:\n",
    "1) name: 可以自己安排寫檔的名稱\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv_file(reservoir_dict_list, length, date_index, year):\n",
    "    name = [\"Sum-Capacity\", \"Out-Daily\", \"Current-Capacity\"]\n",
    "\n",
    "    for index in range(length):\n",
    "        final = {}\n",
    "        for i in reservoir_dict_list[index]:  # check for total data length\n",
    "            if(len(reservoir_dict_list[index][i]) == len(reservoir_dict_list[index]['石門水庫'])):\n",
    "                final[i] = reservoir_dict_list[index][i]\n",
    "        df = pd.DataFrame(final, index = date_index)\n",
    "        file = name[index] + \"-\" + str(year) +\".csv\"  # file name\n",
    "        df.to_csv(file, encoding=\"utf_8_sig\")  # maintain Chinese word(or they might become garbled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "透過從2003年到現在日期建立，可以向網頁求得各別每天的資料。\n",
    "\n",
    "parameter: \n",
    "1) year_list: 透過這個年份的賦值，可以指定查詢的年份\n",
    "2) date_index: 如果日期並不是連續，則可以調整這個 list\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year_list = np.arange(2019,2020)\n",
    "sum_day = 31\n",
    "sub_day = [0, -3, 0, -1, 0, -1, 0, 0, -1, 0, -1, 0]  # sum_day + sub_day = month's days\n",
    "\n",
    "for year in range(len(year_list)):\n",
    "    current_capacity, out, current_water = {}, {}, {}\n",
    "    reservoir_dict_list = [current_capacity, out, current_water]  # data contains several columns' value\n",
    "    date_index = []  # index for DataFrame\n",
    "    \n",
    "    for month in range(1,13):\n",
    "        total = sum_day + sub_day[month-1]\n",
    "        if(year_list[year] % 4 == 0 and month == 2):  # leap year\n",
    "            total = total + 1\n",
    "        for date in range(1, total + 1):\n",
    "            if(month == 4 and date == 18):\n",
    "                break\n",
    "            date_index.append(str(year_list[year]) + \"-\" +  str(month) + \"-\" + str(date))\n",
    "            date_list = [str(year_list[year]), str(month), str(date)]\n",
    "            index_list = [1, 5, 9]  # columns which we want to get\n",
    "            reservoir_dict_list = reservoir_data_search(date_list, reservoir_dict_list, total_reservoir, index_list)  #開始parse資料\n",
    "\n",
    "    print(\"finish:\", year_list[year])  # finish a year\n",
    "    write_csv_file(reservoir_dict_list, len(index_list), date_index, year_list[year])  # write to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### others 其它補充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "針對html當中進行資料的提取\n",
    "(較為複雜，因為要定位該數值在 td 之後的哪個位置，且根據每個水庫名字可能的不同，會有不同的 exception 發生)\n",
    "最後輸出每個水庫某個欄位數值list的年度(365+1天)dictionary\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reservoir_data_management(reservoir, reservoir_dict):\n",
    "    for item in range(len(reservoir)):\n",
    "        reservoir[item] = str(reservoir[item]).replace(\"/\", \"\")\n",
    "        reservoir[item] = reservoir[item].replace(\"<\", \"|\").replace(\">\", \"|\")\n",
    "        start_index = reservoir[item].index(\"|td|\") + 4\n",
    "        try:\n",
    "            end_index = reservoir[item][start_index:start_index+10].index(\"庫\")\n",
    "        except ValueError: \n",
    "            continue\n",
    "        else:\n",
    "            end_index = end_index + 1 + start_index\n",
    "\n",
    "        # find percentage value\n",
    "        try:\n",
    "            number_end_index = reservoir[item].index(\"%\") + 1\n",
    "        except ValueError:\n",
    "            if(reservoir[item][start_index: end_index] not in reservoir_dict.keys()):\n",
    "                reservoir_dict[reservoir[item][start_index: end_index]] = [\"NULL\"]\n",
    "            else:\n",
    "                reservoir_dict[reservoir[item][start_index: end_index]].append(\"NULL\")\n",
    "            continue\n",
    "        else:\n",
    "            number_start_index = reservoir[item][number_end_index-10:number_end_index].index(\"|\") - 9 + number_end_index\n",
    "\n",
    "        value = reservoir[item][number_start_index: number_end_index].replace(\" \", \"\")\n",
    "        name = reservoir[item][start_index: end_index]\n",
    "        if(name in list(reservoir_dict.keys())):\n",
    "            reservoir_dict[name].append(value)\n",
    "        else:\n",
    "            reservoir_dict[name] = []\n",
    "            reservoir_dict[name].append(value)\n",
    "        if(reservoir[item][start_index: end_index] == \"牡丹水庫\"):  # terminal reservoir\n",
    "            break\n",
    "            \n",
    "    return reservoir_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
